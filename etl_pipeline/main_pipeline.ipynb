{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf8bfb-4647-462a-8c05-a194c0e76962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "import glob\n",
    "import urllib3\n",
    "import duckdb\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CONFIGURATION (Environment-Agnostic)\n",
    "# =============================================================================\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Ensures pathing works in both Jupyter Notebooks and standalone .py scripts\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd() \n",
    "\n",
    "DATA_RAW = os.path.join(BASE_DIR, 'data_raw')\n",
    "DATA_PROCESSED = os.path.join(BASE_DIR, 'data_processed')\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "os.makedirs(DATA_RAW, exist_ok=True)\n",
    "os.makedirs(DATA_PROCESSED, exist_ok=True)\n",
    "\n",
    "YEAR = 2024\n",
    "MONTHS = range(1, 13)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. INGESTION (BTS DOWNLOAD & EXTRACTION)\n",
    "# =============================================================================\n",
    "def download_and_extract():\n",
    "    \"\"\"Downloads monthly ZIPs from BTS and extracts raw CSVs for processing.\"\"\"\n",
    "    base_url = \"https://transtats.bts.gov/PREZIP/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{}_{}.zip\"\n",
    "    print(f\"\\n--- [STEP 1] Starting Ingestion for {YEAR} ---\")\n",
    "    \n",
    "    for month in MONTHS:\n",
    "        zip_name = f\"flights_{YEAR}_{month}.zip\"\n",
    "        zip_path = os.path.join(DATA_RAW, zip_name)\n",
    "        \n",
    "        # Download logic with retry mechanism\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f\"Downloading {month}/{YEAR}...\", end=\" \", flush=True)\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    time.sleep(2)\n",
    "                    r = requests.get(base_url.format(YEAR, month), verify=False, stream=True, timeout=60)\n",
    "                    if r.status_code == 200:\n",
    "                        with open(zip_path, 'wb') as f:\n",
    "                            for chunk in r.iter_content(chunk_size=1024):\n",
    "                                f.write(chunk)\n",
    "                        print(\"Success.\")\n",
    "                        break\n",
    "                except Exception:\n",
    "                    time.sleep(5)\n",
    "            else: print(\"Failed.\")\n",
    "\n",
    "    # Extraction logic\n",
    "    print(\"\\nChecking Extraction status...\")\n",
    "    zips = glob.glob(os.path.join(DATA_RAW, \"*.zip\"))\n",
    "    for z in zips:\n",
    "        with zipfile.ZipFile(z, 'r') as zip_ref:\n",
    "            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
    "            for csv in csv_files:\n",
    "                target_path = os.path.join(DATA_RAW, csv)\n",
    "                if not os.path.exists(target_path):\n",
    "                    print(f\"Extracting: {csv}\")\n",
    "                    zip_ref.extract(csv, DATA_RAW)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. VECTORIZED ETL & FINANCIAL MODELING (DUCKDB)\n",
    "# =============================================================================\n",
    "def run_aviation_pipeline():\n",
    "    \"\"\"Vectorized processing of 7.07M records using DuckDB for memory efficiency.\"\"\"\n",
    "    print(f\"\\n--- [STEP 2] Initializing DuckDB Pipeline ---\")\n",
    "    \n",
    "    # Connect to an in-memory DuckDB instance\n",
    "    con = duckdb.connect(':memory:')\n",
    "\n",
    "    # Process Flight Logs: Generate IDs, Standardize Tails, and Apply Financial Logic\n",
    "    print(\"Processing Fact Table (Generating UUIDs & Financial Logic)...\")\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW bts_flights AS \n",
    "        SELECT \n",
    "            -- Upstream Surrogate Key Generation\n",
    "            uuid() AS Flight_ID,\n",
    "            CAST(FlightDate AS DATE) AS FlightDate,\n",
    "            \n",
    "            -- Standardize Tail Number: Force 'N' prefix to prevent join failures\n",
    "            CASE \n",
    "                WHEN Tail_Number IS NULL OR TRIM(Tail_Number) = '' THEN 'UNKNOWN'\n",
    "                WHEN TRIM(Tail_Number) NOT LIKE 'N%' THEN 'N' || TRIM(Tail_Number)\n",
    "                ELSE TRIM(Tail_Number)\n",
    "            END AS Clean_Tail,\n",
    "            \n",
    "            Origin, Dest, Reporting_Airline,\n",
    "            TRY_CAST(AirTime AS DOUBLE) AS AirTime,\n",
    "            TRY_CAST(Cancelled AS INTEGER) AS Cancelled,\n",
    "            \n",
    "            -- Corrected MRL Liability: $0 for Cancelled or Missing AirTime\n",
    "            CASE \n",
    "                WHEN TRY_CAST(Cancelled AS INTEGER) = 1 OR TRY_CAST(AirTime AS DOUBLE) IS NULL THEN 0.0\n",
    "                ELSE ((TRY_CAST(AirTime AS DOUBLE) / 60.0) * 250.0) + 180.0\n",
    "            END AS MRL_Liability,\n",
    "            \n",
    "            -- Zero-Fill Root Cause Delays\n",
    "            COALESCE(TRY_CAST(CarrierDelay AS DOUBLE), 0.0) AS CarrierDelay,\n",
    "            COALESCE(TRY_CAST(WeatherDelay AS DOUBLE), 0.0) AS WeatherDelay,\n",
    "            COALESCE(TRY_CAST(NASDelay AS DOUBLE), 0.0) AS NASDelay,\n",
    "            COALESCE(TRY_CAST(SecurityDelay AS DOUBLE), 0.0) AS SecurityDelay,\n",
    "            COALESCE(TRY_CAST(LateAircraftDelay AS DOUBLE), 0.0) AS LateAircraftDelay\n",
    "            \n",
    "        FROM read_csv_auto('{DATA_RAW}/*.csv', all_varchar=true, header=true, union_by_name=true)\n",
    "    \"\"\")\n",
    "\n",
    "    # Mount Optimized FAA Master Registry (Parquet Integration)\n",
    "    master_parquet = os.path.join(DATA_RAW, 'FAA_Registry_Master.parquet')\n",
    "    if not os.path.exists(master_parquet):\n",
    "        print(\"WARNING: 'FAA_Registry_Master.parquet' not found in 'data_raw'. Asset Audit will skip.\")\n",
    "        has_master = False\n",
    "    else:\n",
    "        print(\"Mounting Optimized FAA Parquet Registry...\")\n",
    "        # DuckDB natively reads Parquet with zero-copy overhead\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE OR REPLACE VIEW faa_master AS\n",
    "            SELECT * FROM read_parquet('{master_parquet}')\n",
    "        \"\"\")\n",
    "        has_master = True\n",
    "\n",
    "    # Export Highly Compressed Parquet Assets\n",
    "    print(\"Exporting optimized Parquet assets to 'data_processed'...\")\n",
    "    con.execute(f\"COPY bts_flights TO '{DATA_PROCESSED}/Aviation_Fact_Table.parquet' (FORMAT PARQUET, CODEC 'SNAPPY')\")\n",
    "    \n",
    "    if has_master:\n",
    "        # Generate Master Dimension only for aircraft present in the active 2024 network\n",
    "        con.execute(f\"\"\"\n",
    "            COPY (\n",
    "                SELECT *\n",
    "                FROM faa_master \n",
    "                WHERE Tail_Number IN (SELECT DISTINCT Clean_Tail FROM bts_flights)\n",
    "            ) TO '{DATA_PROCESSED}/Master_Dim.parquet' (FORMAT PARQUET, CODEC 'SNAPPY')\n",
    "        \"\"\")\n",
    "\n",
    "    # Final Audit Summary to verify results\n",
    "    report = con.execute(\"\"\"\n",
    "        SELECT \n",
    "            SUM(MRL_Liability) as Total_Liability,\n",
    "            COUNT(*) as Total_Rows\n",
    "        FROM bts_flights\n",
    "    \"\"\").fetchone()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" ðŸ“Š FINAL PIPELINE REPORT (7.07M RECORDS) ðŸ“Š\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL PROCESSED ROWS   : {report[1]:,}\")\n",
    "    print(f\"VERIFIED MRL LIABILITY : ${report[0]:,.2f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. EXECUTION GATE\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Download & Extract the raw files (Uncomment if you need to fetch data)\n",
    "    # download_and_extract() \n",
    "    \n",
    "    # 2. Execute the vectorized transformation pipeline\n",
    "    run_aviation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15796611-cf32-41f9-9092-d01aa0744b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
